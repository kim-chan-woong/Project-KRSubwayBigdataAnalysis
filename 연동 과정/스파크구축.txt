참조
https://lsjsj92.tistory.com/422
https://velog.io/@somnode/spark-cluster-install
https://glow153.tistory.com/16

스파크 다운(마스터 서버에서 파일 및 폴더 설정 후 워커 노드에 재배포)
wget https://downloads.apache.org/spark/spark-3.0.2/spark-3.0.2-bin-hadoop3.2.tgz

압축 해제
tar xvfz spark-3.0.2-bin-hadoop3.2.tgz

이름 변경
mv spark-3.0.2-bin-hadoop3.2 spark

스파크 환경 변수 지정
vi /etc/profile.d/spark.sh

export SPARK_HOME=/home/hadoop/spark
export PATH=$PATH:$SPARK_HOME/bin
export PATH=$PATH:$SPARK_HOME/sbin

slaves 설정
vi $SPARK_HOME/conf/slaves
dn01
dn02
dn03

spark-env.sh 설정
vi $SPARK_HOME/conf/spark-env.sh
export JAVA_HOME=/opt/apps/jdk8
# export SPARK_MASTER_HOST=rm01
export SPARK_HOME=/home/hadoop/spark
export HADOOP_HOME=/home/hadoop/hadoop-3.1.0
export YARN_CONF_DIR=/home/hadoop/hadoop-3.1.0/etc/hadoop
export HADOOP_CONF_DIR=/home/hadoop/hadoop-3.1.0/etc/hadoop

spark-defaults.conf 설정
vi $SPARK_HOME/conf/spark-defaults.conf
spark.master yarn
spark.eventLog.enabled true
spark.eventLog.dir file:///home/hadoop/spark/eventLog
spark.history.fs.logDirectory file:///home/hadoop/spark/eventLog

모든 스파크 클러스터에 폴더 생성
mkdir $SPARK_HOME/eventLog

재압축
tar cvfz spark.tar.gz spark

배포(배포 후 권한 이슈 주의!)
scp spark.tar.gz root@dn01:/home/hadoop
scp spark.tar.gz root@dn02:/home/hadoop
scp spark.tar.gz root@dn03:/home/hadoop

압축 해제
tar xvfz spark.tar.gz

모든 하둡 클러스터에 yarn-site.xml 하단 추가
       <property>
                <name>yarn.nodemanager.pmem-check-enabled</name>
                <value>false</value>
       </property>
       <property>
                <name>yarn.nodemanager.vmem-check-enabled</name>
                <value>false</value>
       </property>

실행
$SPARK_HOME/sbin/start-master.sh
$SPARK_HOME/sbin/start-slaves.sh

웹포트
192.168.56.101:8080
192.168.56.101:4040

중지
$SPARK_HOME/sbin/stop-slaves.sh
$SPARK_HOME/sbin/stop-master.sh